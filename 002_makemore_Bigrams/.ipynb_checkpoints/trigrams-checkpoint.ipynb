{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf7a31b0",
   "metadata": {},
   "source": [
    "# makemore: bigram exercises\n",
    "\n",
    "1. watch the \"<u>makemore: bigram</u>\" video on [YouTube](https://www.youtube.com/watch?v=PaCmpygFfXo&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=3)\n",
    "2. come back and complete these exercises to level up :)\n",
    "\n",
    "-----\n",
    "<br><br><a id=\"e1\"></a>\n",
    "# Exercises\n",
    "----\n",
    "1. Train a [**trigram**](#1) language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either [counting](#1a) or a [neural net](#1b). Evaluate the loss; Did it improve over a **bigram** model?\n",
    "2. [Split up the dataset](#2) randomly into <u>80% train set, 10% dev set, 10% test set</u>. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?\n",
    "3. Use the <u>[dev set to tune the strength of smoothing (or regularization)](#3)</u> for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?\n",
    "4. We saw that our 1-hot vectors merely select a row of `W`, so producing these vectors explicitly feels wasteful. Can you delete our use of `F.one_hot` in favor of [simply indexing into rows of `W`](#4)?\n",
    "5. [Look up and use `F.cross_entropy` instead](#5). You should achieve the same result. Can you think of why we'd prefer to use `F.cross_entropy` instead?\n",
    "6. [Meta-exercise!](#6) Think of a fun/interesting exercise and complete it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1d142",
   "metadata": {},
   "source": [
    "----\n",
    "<a id='1'></a>\n",
    "# 1. Trigram Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4ca39",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='1a'></a>\n",
    "## a. Counting Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc433cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427936e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../data/names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874472bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shortest word length in the corpus is: 2\n",
      "the longest word length in the corpus is: 15\n",
      "the length of the corpus document (num of words) is: 32033\n"
     ]
    }
   ],
   "source": [
    "print(f\"the shortest word length in the corpus is: {min(len(w) for w in words)}\")\n",
    "print(f\"the longest word length in the corpus is: {max(len(w) for w in words)}\")\n",
    "print(f\"the length of the corpus document (num of words) is: {len(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e767ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"the 10 most common trigrams: [(('a', 'h', '.'), 1714), (('n', 'a', '.'), \"\n",
      " \"1673), (('a', 'n', '.'), 1509), (('o', 'n', '.'), 1503), (('.', 'm', 'a'), \"\n",
      " \"1453), (('.', 'j', 'a'), 1255), (('.', 'k', 'a'), 1254), (('e', 'n', '.'), \"\n",
      " \"1217), (('l', 'y', 'n'), 976), (('y', 'n', '.'), 953)]\")\n"
     ]
    }
   ],
   "source": [
    "t = {}\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        trigram = (ch1, ch2, ch3)\n",
    "        t[trigram] = t.get(trigram, 0) + 1\n",
    "pprint(f'the 10 most common trigrams: {sorted(t.items(), key = lambda kv: -kv[1])[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac7d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        N[ix1, ix2, ix3] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0389fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 207, 190,  31, 366,  55,  21,  17,  91, 154,  27,  75, 632, 384,\n",
       "        623,  10,  17,   9, 482, 194,  72, 152, 243,   6,  27, 173, 152],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8981bc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27]), 18, 'r')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0][1].float()    \n",
    "p = p / p.sum()\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "p.shape, ix, itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e3d8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quia.\n",
      "yu.\n",
      "quinslyntien.\n",
      "nolliahi.\n",
      "ha.\n"
     ]
    }
   ],
   "source": [
    "P = (N+1).float() \n",
    "P /= P.sum(2, keepdim=True) \n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix, jx = 0, 0\n",
    "    while True:\n",
    "        p = P[ix][jx]\n",
    "        next_letter = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        ix = jx\n",
    "        jx = next_letter\n",
    "        out.append(itos[next_letter])\n",
    "        if next_letter == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba58a47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "log_likelihood = -410414.9688\n",
      "negative log_likelihood = 410414.9688\n",
      "\n",
      "average negative log_likelihood = 2.0927\n",
      "CPU times: user 1.51 s, sys: 19.2 ms, total: 1.53 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        \n",
    "print(f'\\nlog_likelihood = {log_likelihood:.4f}')\n",
    "nll = -log_likelihood\n",
    "print(f'negative log_likelihood = {nll:.4f}\\n')\n",
    "avg_nll = nll/n\n",
    "print(f'average negative log_likelihood = {avg_nll:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca260350",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='1b'></a>\n",
    "## b. Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b358a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigrams(words_list:list):\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for w in words_list:\n",
    "        chs = ['.'] + list(w) + ['.']\n",
    "        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "            ix1 = stoi[ch1]\n",
    "            ix2 = stoi[ch2]\n",
    "            ix3 = stoi[ch3]\n",
    "            #print(ch1, ch2, ch3)\n",
    "            xs.append([ix1, ix2])\n",
    "            ys.append(ix3)\n",
    "\n",
    "    xs = torch.tensor(xs) \n",
    "    ys = torch.tensor(ys)\n",
    "    \n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b115a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and initialize the neural net\n",
    "xnn, ynn = create_trigrams(words)\n",
    "num = ynn.nelement()\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W_nn = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c3980d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num == ynn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bca9a907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.245729923248291\n",
      "2.24568247795105\n",
      "2.245635747909546\n",
      "2.2455894947052\n",
      "\n",
      "average negative log_likelihood = 2.2456\n",
      "\n",
      "CPU times: user 48.2 s, sys: 7.36 s, total: 55.6 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_iter_nn, lr_nn, C_nn = 250, 50, 0.0\n",
    "losses_nn = []\n",
    "# gradient descent\n",
    "for k in range(n_iter_nn):\n",
    "\n",
    "    # forward pass\n",
    "    xenc_nn = F.one_hot(xnn, num_classes=27).float()            # input to the network: one-hot encoding\n",
    "    logits_nn = xenc_nn.view(-1, 27*2) @ W_nn                   # predict log-counts\n",
    "    counts_nn = logits_nn.exp()                                 # counts, equivalent to N\n",
    "    probs_nn = counts_nn / counts_nn.sum(1, keepdim=True)       # probabilities for next character\n",
    "    loss_nn = -probs_nn[torch.arange(num), ynn].log().mean() + C_nn*(W_nn**2).mean() \n",
    "    #print(loss_nn.item())\n",
    "    losses_nn.append(loss_nn)\n",
    "    if k > (n_iter_nn - 5):\n",
    "        print(loss_nn.item())\n",
    "\n",
    "    # backward pass\n",
    "    W_nn.grad = None # set to zero the gradient\n",
    "    loss_nn.backward()\n",
    "\n",
    "    # update\n",
    "    W_nn.data += -lr_nn * W_nn.grad\n",
    "print(f'\\naverage negative log_likelihood = {loss_nn.item():.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80738fc2",
   "metadata": {},
   "source": [
    "----\n",
    "<br><br><a id='2'></a>\n",
    "# 2. Model Validation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44a43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(xs, ys, train_percent:int, val_percent:int, test_percent:int):\n",
    "    '''\n",
    "    split dataset into train, validation and test sets\n",
    "    '''\n",
    "    assert train_percent + val_percent + test_percent == 100\n",
    "    \n",
    "    total = len(xs)\n",
    "    train_end, val_end = int(total * train_percent / 100), int(total * (train_percent + val_percent) / 100)\n",
    "    Xtr, Ytr = xs[:train_end],  ys[:train_end]\n",
    "    Xval, Yval = xs[train_end:val_end],  ys[train_end:val_end]\n",
    "    Xtest, Ytest = xs[val_end:],  ys[val_end:]\n",
    "    \n",
    "    assert len(Xtr) == len(Ytr)\n",
    "    assert len(Xval) == len(Yval)\n",
    "    assert len(Xtest) == len(Ytest)\n",
    "    \n",
    "    return Xtr, Ytr, Xval, Yval, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b12dee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnn2, ynn2 = create_trigrams(words)\n",
    "x_tr, y_tr, x_val, y_val, x_test, y_test = data_split(xnn2, ynn2, 80, 10, 10)\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W_nn2 = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10047666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80% training set\n",
      "10% validation set\n",
      "10% test set\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(x_tr)/len(xnn2)*100:.0f}% training set')\n",
    "print(f'{len(x_val)/len(xnn2)*100:.0f}% validation set')\n",
    "print(f'{len(x_test)/len(xnn2)*100:.0f}% test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "232a9908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20723819732666\n",
      "2.2071897983551025\n",
      "2.207141637802124\n",
      "2.207094192504883\n",
      "\n",
      "train_loss (final): 2.2071\n",
      "\n",
      "CPU times: user 37.7 s, sys: 6.08 s, total: 43.8 s\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "losses_tr = []\n",
    "n_iter_tr, lr_tr, C_tr = 250, 50, 0.0\n",
    "\n",
    "# gradient descent\n",
    "for k in range(n_iter_tr):\n",
    "\n",
    "    # forward pass\n",
    "    xenc_tr = F.one_hot(x_tr, num_classes=27).float()            \n",
    "    logits_tr = xenc_tr.view(-1, 27*2) @ W_nn2                 \n",
    "    counts_tr = logits_tr.exp()                                 \n",
    "    probs_tr = counts_tr / counts_tr.sum(1, keepdim=True)  + C_tr*(W_nn2**2).mean()    \n",
    "    loss_tr = -probs_tr[torch.arange(y_tr.shape[0]), y_tr].log().mean() \n",
    "    #print(loss_tr.item())\n",
    "    losses_tr.append(loss_tr)\n",
    "    if k > (n_iter_tr - 5):\n",
    "        print(loss_tr.item())\n",
    "\n",
    "    # backward pass\n",
    "    W_nn2.grad = None # set to zero the gradient\n",
    "    loss_tr.backward()\n",
    "\n",
    "    # update\n",
    "    W_nn2.data += -lr_tr * W_nn2.grad\n",
    "    \n",
    "#print(f'\\naverage negative log_likelihood = {loss_tr.item():.4f}\\n')\n",
    "\n",
    "print(f\"\\ntrain_loss (final): {losses_tr[-1]:.4f}\\n\")\n",
    "plt.plot(losses_tr)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Loss on training data\")\n",
    "plt.grid() \n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c5ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss: 2.4321\n"
     ]
    }
   ],
   "source": [
    "xenc_val = F.one_hot(x_val, num_classes=27).float()\n",
    "logits_val = xenc_val.view(-1, 27*2) @ W_nn2\n",
    "counts_val = logits_val.exp()\n",
    "probs_val = counts_val/ counts_val.sum(1, keepdim=True)\n",
    "\n",
    "loss_val = -probs_val[torch.arange(y_val.shape[0]), y_val].log().mean()\n",
    "print(f\"validation loss: {loss_val.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8cbace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 2.4324\n"
     ]
    }
   ],
   "source": [
    "xenc_test = F.one_hot(x_test, num_classes=27).float()\n",
    "logits_test = xenc_test.view(-1, 27*2) @ W_nn2\n",
    "counts_test = logits_test.exp()\n",
    "probs_test = counts_test/ counts_test.sum(1, keepdim=True)\n",
    "\n",
    "loss_test = -probs_test[torch.arange(y_test.shape[0]), y_test].log().mean()\n",
    "print(f\"test loss: {loss_test.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049ff24",
   "metadata": {},
   "source": [
    "---\n",
    "For the <u>trigram model</u>, the loss after training the model on the <u>**training set**</u> was **`2.2071`**. Evaluating the model on the **<u>validation</u>** and **<u>test</u>** set yielded losses of **`2.4321`** and **`2.4324`** respectively. The  test and validation losses are very similar and marginally higher than the traiing loss so that means the model is <u>not overfitting</u> (generalizes well to new unseen data: **model robustness**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7c0fa",
   "metadata": {},
   "source": [
    "----\n",
    "<br><br><a id='3'></a>\n",
    "# 3. Regularization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bab9b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tr, num_val, num_test = y_tr.nelement(), y_val.nelement(), y_test.nelement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a52577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [00:16<02:41, 16.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0000 ---> train loss: 2.2110,    validation loss: 2.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 2/11 [00:34<02:30, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0010 ---> train loss: 2.2108,    validation loss: 2.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 3/11 [00:53<02:18, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0100 ---> train loss: 2.2212,    validation loss: 2.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▋      | 4/11 [01:14<02:09, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0200 ---> train loss: 2.2312,    validation loss: 2.4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 5/11 [01:30<01:46, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0500 ---> train loss: 2.2539,    validation loss: 2.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 6/11 [01:45<01:24, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.0750 ---> train loss: 2.2698,    validation loss: 2.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▎   | 7/11 [02:04<01:10, 17.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.1000 ---> train loss: 2.2833,    validation loss: 2.4390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 8/11 [02:19<00:50, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.2500 ---> train loss: 2.3468,    validation loss: 2.4605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 9/11 [02:34<00:32, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.3000 ---> train loss: 2.3635,    validation loss: 2.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 10/11 [02:51<00:16, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.4000 ---> train loss: 2.3929,    validation loss: 2.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [03:06<00:00, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For regularization parameter = 0.5000 ---> train loss: 2.4185,    validation loss: 2.4913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reg_param_list = [0, 0.001, 0.01, 0.02, 0.05, 0.075, 0.1, 0.25, 0.3, 0.4, 0.5]\n",
    "#reg_param_list = np.geomspace(0.001, 1, 12)\n",
    "\n",
    "loss_dict = {} # <reg_strength: [final train loss, final val loss]>\n",
    "n_iter = 200\n",
    "lr = 50\n",
    "\n",
    "for C in tqdm(reg_param_list):\n",
    "    # Initialize model & losses\n",
    "    W_reg = torch.randn((27*2, 27), generator=g, requires_grad=True)\n",
    "    #tr_losses, val_losses= [], []\n",
    "    \n",
    "    # gradient descent\n",
    "    for k in range(n_iter):\n",
    "\n",
    "        # forward pass\n",
    "        xenc = F.one_hot(x_tr, num_classes=27).float()       \n",
    "        logits = xenc.view(-1, 27*2) @ W_reg                 \n",
    "        counts = logits.exp()                             \n",
    "        probs = counts / counts.sum(1, keepdim=True)     \n",
    "        tr_loss = -probs[torch.arange(num_tr), y_tr].log().mean() + C*(W_reg**2).mean() \n",
    "        #print(loss.item())\n",
    "        #tr_losses.append(tr_loss)\n",
    "\n",
    "        # Zero grad & backward pass\n",
    "        W_reg.grad = None \n",
    "        tr_loss.backward()\n",
    "\n",
    "        # update\n",
    "        W_reg.data += -lr * W_reg.grad     \n",
    "\n",
    "\n",
    "    xenc_val = F.one_hot(x_val, num_classes=27).float()      \n",
    "    logits = xenc_val.view(-1, 27*2) @ W_reg                   \n",
    "    counts = logits.exp()                             \n",
    "    probs = counts / counts.sum(1, keepdim=True)     \n",
    "    val_loss = -probs[torch.arange(num_val), y_val].log().mean()\n",
    "\n",
    "       \n",
    "    print(f'For regularization parameter = {C:.4f} ---> train loss: {tr_loss.item():.4f},\\\n",
    "    validation loss: {val_loss.item():.4f}')\n",
    "    \n",
    "    _tr_loss = np.round(tr_loss.item(), decimals=4)\n",
    "    _val_loss = np.round(val_loss.item(), decimals=4)\n",
    "    _C = np.round(C, decimals=4)\n",
    "    loss_dict[_C] = [_tr_loss, _val_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5785dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [2.211, 2.4363],\n",
       " 0.001: [2.2108, 2.4331],\n",
       " 0.01: [2.2212, 2.4338],\n",
       " 0.02: [2.2312, 2.4321],\n",
       " 0.05: [2.2539, 2.4331],\n",
       " 0.075: [2.2698, 2.4351],\n",
       " 0.1: [2.2833, 2.439],\n",
       " 0.25: [2.3468, 2.4605],\n",
       " 0.3: [2.3635, 2.4672],\n",
       " 0.4: [2.3929, 2.4798],\n",
       " 0.5: [2.4185, 2.4913]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "273f1647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(f\"Effect of Regularization/Smoothing on Trigram Model\")\n",
    "plt.plot(list(loss_dict.keys()), [train_loss for train_loss, _ in loss_dict.values()], \"o--\", label=\"train\")\n",
    "plt.plot(list(loss_dict.keys()), [val_loss for _, val_loss in loss_dict.values()], \"o--\", label=\"val\")\n",
    "plt.xlabel(\"Regularization Strength, C\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24260e78",
   "metadata": {},
   "source": [
    "Increasing the **regularization parameter `C`** increases both the validation and training losses, but <u>the training losses grow faster than the validation losses.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae7396",
   "metadata": {},
   "source": [
    "----\n",
    "<br><br><a id='4'></a>\n",
    "# 4. Indexing into Rows of W (Discard One-Hot Encoding)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55741787",
   "metadata": {},
   "source": [
    "Utilising the inputs **`xnn`** and weight matrix **`W_nn`** from problem 1b (neural network approach for trigram LM). Let's compare the results for one-hot encoding **`xnn`**, (**`xenc_nn`**) and indexing into rows of **`W_nn`**.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e84e0a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss via indexing into rows of W: 2.2455\n"
     ]
    }
   ],
   "source": [
    "logits_idx = W_nn[xnn[:, 0]] + W_nn[xnn[:, 1] + 27]\n",
    "counts_idx = logits_idx.exp()\n",
    "probs_idx = counts_idx / counts_idx.sum(1, keepdim=True)\n",
    "loss_idx = -1 * probs_idx[torch.arange(ynn.shape[0]), ynn].log().mean()\n",
    "#loss_idx\n",
    "\n",
    "print(f\"validation loss via indexing into rows of W: {loss_idx.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19071481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation loss via one-hot encoding: 2.2455\n"
     ]
    }
   ],
   "source": [
    "logits_ohe = xenc_nn.view(-1, 27*2) @ W_nn\n",
    "counts_ohe = logits_ohe.exp()\n",
    "probs_ohe = counts_ohe / counts_ohe.sum(1, keepdim=True)\n",
    "loss_ohe = -1 * probs_ohe[torch.arange(ynn.shape[0]), ynn].log().mean()\n",
    "#loss_ohe\n",
    "\n",
    "print(f\"validation loss via one-hot encoding: {loss_ohe.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5071830",
   "metadata": {},
   "source": [
    "<br>As we can see from the cells above, we get the **same results** using either one-hot encoding or indexing into rows of W."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b25f2",
   "metadata": {},
   "source": [
    "----\n",
    "<br><br><a id='5'></a>\n",
    "# 5. `F.cross_entropy`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "990ebd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Negative Log Likelihood Loss: 2.2455\n"
     ]
    }
   ],
   "source": [
    "logits = xenc_nn.view(-1, 2*27) @ W_nn\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "loss = -probs[torch.arange(ynn.shape[0]), ynn].log().mean()\n",
    "print(f\"Average Negative Log Likelihood Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a77945a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 2.2455\n"
     ]
    }
   ],
   "source": [
    "loss_ce = F.cross_entropy(logits, ynn)\n",
    "print(f\"Cross Entropy Loss: {loss_ce.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b309f6d",
   "metadata": {},
   "source": [
    "We get the same results using both methods. However, `F.cross_entropy` is preferable because it combines the softmax step and loss function step together at once. Basically, `F.cross_entropy` incorporates transforming the neural net outputs to probabilities with calculating the loss in one step (**`logits`** -> **`losses`**)\n",
    "\n",
    "\n",
    "- <u>NN outputs to probabilities</u>: **`logits`** -> [exp(x)] -> **`counts`** -> [normalize(x)] -> **`probs`**\n",
    "- <u>Probabilities to losses</u>: **`probs`** -> [Average negative log likelihood(x)] -> **`losses`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd09f4",
   "metadata": {},
   "source": [
    "----\n",
    "<br><br><a id='6'></a>\n",
    "# 6. meta-exercise: PyTorch Base Class for all Neural Network Modules\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b6351",
   "metadata": {},
   "source": [
    "Implementation steps of class:\n",
    "- Initialize\n",
    "    * Apply a linear transformation to incoming data: `y = xA.T + b`, using `torch.nn.Linear`\n",
    "    * Initialize weights with normal distribution (mean of 0 and STD of 1)\n",
    "- Forward function\n",
    "    * No activation function \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ad688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        #print(ch1, ch2, ch3)\n",
    "        xs.append([ix1, ix2])\n",
    "        ys.append(ix3)\n",
    "\n",
    "xs = torch.tensor(xs) \n",
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6625f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(2*27, 27) # first fully connected layer of MLP\n",
    "        torch.nn.init.normal_(self.fc1.weight, mean=0, std=1)\n",
    "        #torch.nn.init.xavier_uniform(self.fc1.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = W_nn[x[:, 0]] + W_nn[x[:, 1] + 27]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e82b518e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 249 iterations, the loss is 2.2455\n"
     ]
    }
   ],
   "source": [
    "C = 0\n",
    "model = MLP()\n",
    "# gradient descent\n",
    "for k in range(250):\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(xs)\n",
    "    loss = F.cross_entropy(logits, ys) \n",
    "    loss += C * (model.fc1.weight ** 2).mean() # added regularization term\n",
    "    \n",
    "#     if k % 10 == 0:\n",
    "#         print(f'After {k} iterations, the loss is {loss.item():.4f}')\n",
    "\n",
    "    # backward pass\n",
    "    model.fc1.zero_grad() # set to zero the gradient (reset gradients of the layer)\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    model.fc1.weight.data += -50 * model.fc1.weight.grad\n",
    "print(f\"After {k} iterations, the loss is {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2df75316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 1.7855,  0.3460, -1.2854,  ...,  0.5336, -0.8839,  0.3031],\n",
       "         [ 0.1225, -1.0614,  1.0801,  ..., -0.3535, -0.5087, -1.2049],\n",
       "         [-0.0594, -0.4437,  0.3638,  ...,  0.1334,  0.1140,  0.4028],\n",
       "         ...,\n",
       "         [-1.1852,  1.0893, -1.8360,  ...,  0.0390,  1.0074,  0.5208],\n",
       "         [ 1.0159, -0.2812,  1.5159,  ..., -0.1665,  1.3235, -0.6612],\n",
       "         [ 2.1103,  0.6758, -1.7507,  ...,  0.7648,  0.6888, -0.0393]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0118,  0.0219,  0.0048,  0.0952, -0.0755, -0.1241,  0.0293, -0.0502,\n",
       "         -0.1163,  0.0890,  0.1085, -0.1187, -0.0349,  0.0860, -0.1105, -0.0938,\n",
       "         -0.0551, -0.1208, -0.0525, -0.0991, -0.0487,  0.1044, -0.0580, -0.1296,\n",
       "          0.1280, -0.0386, -0.1206], requires_grad=True))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight, model.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db5e4df4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 249 iterations, the loss is 2.2455\n"
     ]
    }
   ],
   "source": [
    "C = 0\n",
    "model2 = MLP()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr = 50)\n",
    "\n",
    "\n",
    "# gradient descent\n",
    "for k in range(250):\n",
    "\n",
    "    # forward pass\n",
    "    logits = model(xs)\n",
    "    loss = F.cross_entropy(logits, ys) \n",
    "    loss += C * (model.fc1.weight.data ** 2).mean() # added regularization term\n",
    "    \n",
    "#     if k % 10 == 0:\n",
    "#         print(f'After {k} iterations, the loss is {loss.item():.4f}')\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "print(f\"After {k} iterations, the loss is {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53d48aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([27, 54]), torch.Size([27]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fc1.weight.shape, model2.fc1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23f57325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-1.1215, -0.0396,  0.1958,  ..., -0.2544,  0.4298, -0.4357],\n",
       "         [ 1.3369, -0.1873, -1.1479,  ..., -0.8545,  0.0814,  2.1752],\n",
       "         [ 0.1292,  1.4875,  0.2979,  ...,  0.1874,  0.9836, -0.0892],\n",
       "         ...,\n",
       "         [-0.6958,  0.1216, -1.8677,  ...,  1.2131,  0.4728, -0.7404],\n",
       "         [ 0.8460,  0.1320,  0.7196,  ..., -0.0559, -0.4908, -0.4020],\n",
       "         [-0.6621,  1.7270, -1.1435,  ...,  1.6317,  0.1695,  0.8134]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0715, -0.0081, -0.0726, -0.0865,  0.0413, -0.1155, -0.0556, -0.1025,\n",
       "         -0.0778,  0.0568,  0.1281, -0.0204, -0.0799,  0.0951, -0.0248,  0.0988,\n",
       "          0.1246, -0.0578, -0.0071,  0.0510,  0.0348, -0.1114,  0.0883, -0.0448,\n",
       "         -0.0798, -0.1314, -0.0539], requires_grad=True))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fc1.weight, model2.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ee1c759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of logits: torch.Size([196113, 27])\n",
      "Shape of ynn: torch.Size([196113])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2455, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "logits = model2(xnn)\n",
    "print(\"Shape of logits:\", logits.shape)\n",
    "print(\"Shape of ynn:\", ynn.shape)\n",
    "loss = F.cross_entropy(logits, ynn)\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
